{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1258df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "directory = \".\"\n",
    "\n",
    "#query = \"find smallest grade in enrollments\"\n",
    "query = \"get Grade, Major where Grade is not null\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826f2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f14bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_function(directory, query):\n",
    "\n",
    "    csv_folder = directory \n",
    "\n",
    "    sample_queries = [query]\n",
    "\n",
    "    test_queries = [query]\n",
    "\n",
    "\n",
    "    def check_join_needed(directory_path, query):\n",
    "        \"\"\"\n",
    "        Checks if the query columns are spread across multiple CSV files.\n",
    "\n",
    "        Parameters:\n",
    "            directory_path (str): Path to the directory containing CSV files.\n",
    "            query (str): User query containing column names and random words.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if a join is needed (columns spread across multiple files), False otherwise.\n",
    "        \"\"\"\n",
    "        # Extract column names from the query\n",
    "        query_columns = set(query.split())\n",
    "\n",
    "        # Dictionary to map file names to their columns\n",
    "        file_columns_map = {}\n",
    "\n",
    "        # Iterate over all files in the directory\n",
    "        for file in os.listdir(directory_path):\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(directory_path, file)\n",
    "                try:\n",
    "                    # Read only the header of the CSV to get column names\n",
    "                    df = pd.read_csv(file_path, nrows=0)\n",
    "                    file_columns_map[file] = set(df.columns)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "        # Identify which file contains which columns\n",
    "        files_with_columns = []\n",
    "\n",
    "        for column in query_columns:\n",
    "            for file, columns in file_columns_map.items():\n",
    "                if column in columns:\n",
    "                    files_with_columns.append(file)\n",
    "                    break\n",
    "\n",
    "        # Check if columns are spread across multiple files\n",
    "        unique_files = set(files_with_columns)\n",
    "\n",
    "        join_needed = len(unique_files) > 1\n",
    "        return join_needed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    check_join_needed = check_join_needed(directory, query)\n",
    "\n",
    "    if check_join_needed == True:\n",
    "\n",
    "        print(\"Join\")\n",
    "\n",
    "        def build_column_table_mapping(csv_folder):\n",
    "            \"\"\"\n",
    "            Scans all CSV files in the given folder to build a mapping of columns to tables.\n",
    "            :param csv_folder: Path to the folder containing CSV files (each file is a table).\n",
    "            :return: Dictionary mapping column names to table names and a dictionary of dataframes for each table.\n",
    "            \"\"\"\n",
    "            mapping = defaultdict(list)\n",
    "            tables = {}\n",
    "            for file in glob.glob(f\"{csv_folder}/*.csv\"):\n",
    "                table_name = file.split(\"/\")[-1].replace(\".csv\", \"\")\n",
    "                df = pd.read_csv(file)\n",
    "                tables[table_name] = df\n",
    "                for column in df.columns:\n",
    "                    mapping[column].append(table_name)\n",
    "            return mapping, tables\n",
    "        \n",
    "        import re\n",
    "        \n",
    "        def auto_generate_query(raw_query, column_table_mapping, tables):\n",
    "            \"\"\"\n",
    "            Automatically resolves and rewrites the query by determining joins and conditions based on column-table mapping.\n",
    "            :param raw_query: User-specified natural language query.\n",
    "            :param column_table_mapping: Dictionary mapping columns to tables.\n",
    "            :param tables: Dictionary containing table dataframes for column checks.\n",
    "            :return: Rewritten SQL query with compact formatting.\n",
    "            \"\"\"\n",
    "            # Define a single regex pattern using reusable keywords\n",
    "            KEYWORDS_PATTERN = r\"(?:find|list|determine|show|get|retrieve|give me|provide|display|fetch|what are|show me)?\\s*\"\n",
    "            CONTEXT_PATTERN = r\"(?:from|in|on|of)?\\s*(?:context)?\"\n",
    "            QUERY_PATTERN = re.compile(\n",
    "                rf\"{KEYWORDS_PATTERN}(.+?)\\s*{CONTEXT_PATTERN}\\s*(?:where|if|with|satisfying|that (?:meet|fulfill))\\s+(.+)\",\n",
    "                re.IGNORECASE,\n",
    "            )\n",
    "\n",
    "            # SQL keywords to normalize\n",
    "            SQL_KEYWORDS = [\"between\", \"like\", \"is not null\", \"is null\", \"and\", \"or\", \"not\", \"in\", \"exists\"]\n",
    "\n",
    "            # Stop words to remove\n",
    "            STOP_WORDS = {\"a\", \"an\", \"the\"}\n",
    "\n",
    "            # Preprocess raw query to remove stop words\n",
    "            def preprocess_query(query):\n",
    "                words = query.split()\n",
    "                return \" \".join(word for word in words if word.lower() not in STOP_WORDS)\n",
    "\n",
    "            # Preprocess the query\n",
    "            raw_query = preprocess_query(raw_query)\n",
    "\n",
    "            # Match the query\n",
    "            match = QUERY_PATTERN.match(raw_query)\n",
    "            if not match:\n",
    "                raise ValueError(\"Query format is invalid. Please use a supported structure.\")\n",
    "\n",
    "            selected_columns = match.group(1).split(\", \")\n",
    "            condition = match.group(2).strip()\n",
    "\n",
    "            # Resolve tables for selected columns\n",
    "            columns_with_tables = []\n",
    "            required_tables = set()\n",
    "            for column in selected_columns:\n",
    "                if column in column_table_mapping:\n",
    "                    table_name = column_table_mapping[column][0]  # Take the first match\n",
    "                    columns_with_tables.append(f\"{table_name}.{column}\")\n",
    "                    required_tables.add(table_name)\n",
    "                else:\n",
    "                    raise ValueError(f\"Column '{column}' not found in any table.\")\n",
    "\n",
    "            # Normalize SQL keywords in the condition\n",
    "            for keyword in SQL_KEYWORDS:\n",
    "                condition = re.sub(rf\"\\b{keyword}\\b\", keyword.upper(), condition, flags=re.IGNORECASE)\n",
    "\n",
    "            # Determine join conditions\n",
    "            join_conditions = []\n",
    "            required_tables = list(required_tables)\n",
    "            for i in range(len(required_tables) - 1):\n",
    "                table_a, table_b = required_tables[i], required_tables[i + 1]\n",
    "                common_columns = set(tables[table_a].columns).intersection(tables[table_b].columns)\n",
    "\n",
    "                # Use only one common column for a simple join\n",
    "                if len(common_columns) < 1:\n",
    "                    raise ValueError(f\"No common column found to join '{table_a}' and '{table_b}'.\")\n",
    "\n",
    "                common_column = next(iter(common_columns))  # Take the first common column\n",
    "                join_conditions.append(f\"{table_a}.{common_column} = {table_b}.{common_column}\")\n",
    "\n",
    "            # Construct the SQL query\n",
    "            formatted_query = f\"SELECT {', '.join(columns_with_tables)}\\nFROM {required_tables[0]}\"\n",
    "            for i in range(1, len(required_tables)):\n",
    "                formatted_query += f\"\\nJOIN {required_tables[i]} ON {join_conditions[i - 1]}\"\n",
    "            formatted_query += f\"\\nWHERE {condition};\"\n",
    "\n",
    "            return formatted_query.strip()\n",
    "\n",
    "        column_table_mapping, tables = build_column_table_mapping(csv_folder)\n",
    "\n",
    "\n",
    "        # Process sample queries\n",
    "        for query in sample_queries:\n",
    "            try:\n",
    "                resolved_query = auto_generate_query(query, column_table_mapping, tables)\n",
    "                print(f\"Input: {query}\\nResolved Query:\\n{resolved_query}\\n\")\n",
    "            except ValueError as e:\n",
    "                print(f\"Error processing query '{query}': {e}\\n\")\n",
    "\n",
    "    elif check_join_needed == False:\n",
    "\n",
    "        print(\"No Join\")\n",
    "\n",
    "        import re\n",
    "        import textwrap\n",
    "\n",
    "        # Define templates with proper indentation using textwrap.dedent\n",
    "        query_templates = [\n",
    "            # Smallest value pattern\n",
    "            (\n",
    "                r\"(?:find|list)?\\s*smallest (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT {m.group(1)}, MIN({m.group(1)}) AS min_value\n",
    "                    FROM {m.group(2)}\n",
    "                    GROUP BY {m.group(1)}\n",
    "                    ORDER BY min_value ASC\n",
    "                    LIMIT 1;\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Largest value pattern\n",
    "            (\n",
    "                r\"(?:find|list)?\\s*largest (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT {m.group(1)}, MAX({m.group(1)}) AS max_value\n",
    "                    FROM {m.group(2)}\n",
    "                    GROUP BY {m.group(1)}\n",
    "                    ORDER BY max_value DESC\n",
    "                    LIMIT 1;\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Count entries in a table\n",
    "            (\n",
    "                r\"(?:find|count)?\\s*entries in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT COUNT(*) AS entry_count\n",
    "                    FROM {m.group(1)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Find all unique values\n",
    "            (\n",
    "                r\"(?:find|list)?\\s*unique (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT DISTINCT {m.group(1)}\n",
    "                    FROM {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Define reusable keyword pattern\n",
    "        KEYWORDS_PATTERN = r\"(?:find|list|determine|show|get|retrieve|give me\\s*)?\"\n",
    "\n",
    "        query_templates += [\n",
    "            # Sum of a column\n",
    "            (\n",
    "                r\"(?:find|calculate)?\\s*sum of (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT SUM({m.group(1)}) AS total_sum\n",
    "                    FROM {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Average of a column\n",
    "            (\n",
    "                r\"(?:find|calculate)?\\s*average of (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT AVG({m.group(1)}) AS average_value\n",
    "                    FROM {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Minimum value in a column\n",
    "            (\n",
    "                r\"(?:find|list)?\\s*minimum (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT MIN({m.group(1)}) AS min_value\n",
    "                    FROM {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Maximum value in a column\n",
    "            (\n",
    "                r\"(?:find|list)?\\s*maximum (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT MAX({m.group(1)}) AS max_value\n",
    "                    FROM {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Count distinct values in a column\n",
    "            (\n",
    "                r\"(?:find|count)?\\s*distinct (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT COUNT(DISTINCT {m.group(1)}) AS distinct_count\n",
    "                    FROM {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Find all rows where a column equals a value\n",
    "            (\n",
    "                r\"(?:find|list)?\\s*rows where (.+) equals (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT *\n",
    "                    FROM {m.group(3)}\n",
    "                    WHERE {m.group(1)} = {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Find all rows where a column is greater than a value\n",
    "            (\n",
    "                r\"(?:find|list)?\\s*rows where (.+) greater than (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT *\n",
    "                    FROM {m.group(3)}\n",
    "                    WHERE {m.group(1)} > {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Find all rows where a column is less than a value\n",
    "            (\n",
    "                r\"(?:find|list)?\\s*rows where (.+) less than (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT *\n",
    "                    FROM {m.group(3)}\n",
    "                    WHERE {m.group(1)} < {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Count rows with a specific condition\n",
    "            (\n",
    "                r\"(?:find|count)?\\s*rows where (.+) equals (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT COUNT(*) AS row_count\n",
    "                    FROM {m.group(3)}\n",
    "                    WHERE {m.group(1)} = {m.group(2)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "\n",
    "            # Find the top N rows by a column\n",
    "            (\n",
    "                rf\"{KEYWORDS_PATTERN}\\s*top (\\d+) rows by (.+) in (.+)\",\n",
    "                lambda m: textwrap.dedent(f\"\"\"\n",
    "                    SELECT *\n",
    "                    FROM {m.group(3)}\n",
    "                    ORDER BY {m.group(2)} DESC\n",
    "                    LIMIT {m.group(1)};\n",
    "                \"\"\").strip()\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Function to match and generate queries\n",
    "        def generate_query(user_query, templates):\n",
    "            for pattern, query_func in templates:\n",
    "                match = re.match(pattern, user_query, re.IGNORECASE)\n",
    "                if match:\n",
    "                    return query_func(match)\n",
    "            return None\n",
    "\n",
    "\n",
    "        # Generate and print SQL queries for test queries\n",
    "        for user_query in test_queries:\n",
    "            sql_query = generate_query(user_query, query_templates)\n",
    "            if sql_query:\n",
    "                #print(f\"User Query: {user_query}\")\n",
    "                #print(f\"Generated SQL Query:\\n{sql_query}\\n\")\n",
    "                print(sql_query)\n",
    "            #else:\n",
    "                #print(f\"No match found for query: {user_query}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b2eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get Grade, Major where Grade is not null\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5176b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join\n",
      "Input: get Grade, Major where Grade is not null\n",
      "Resolved Query:\n",
      "SELECT enrollments.Grade, students.Major\n",
      "FROM enrollments\n",
      "JOIN students ON enrollments.StudentID = students.StudentID\n",
      "WHERE Grade IS NOT NULL;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_function(directory, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f4aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
